{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # 교육 관련 데이터 제공(교육통계 서비스)\n",
    "# # https://kess.kedi.re.kr/post/6684877?itemCode=04&menuId=m_02_04_02&code=&wors=%EC\n",
    "\n",
    "# df = pd.read_excel('./data/고등교육기관 주소록_2019.xlsx',header=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7912aeb3af7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_1\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'연도'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2019\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'시도'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'부산'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'학교명'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'주소'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# df_1 =df[(df['연도'] == 2019) & (df['시도'] == '부산')].loc[:, ['학교명', '주소']]\n",
    "# df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-3-95e8aa22edad>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-95e8aa22edad>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    res = requests.get(url, headers=headers)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "# KAKAO_API_KEY = ''\n",
    "# url = '''\n",
    "# https://dapi.kakao.com/v2/local/search/address.json?query={0}\n",
    "# '''.format(query)\n",
    "#     res = requests.get(url, headers=headers)\n",
    "#     res = res.json()\n",
    "#     print(res['documents'][0]['address_name'],\n",
    "#           res['documents'][0]['y'],\n",
    "#           res['documents'][0]['x'],\n",
    "#           res['documents'][0]['place_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-246edfe115bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0muniversity_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maddr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetGetGeocoder\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0maddr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'주소'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_1' is not defined"
     ]
    }
   ],
   "source": [
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# university_list = []\n",
    "# for i, addr, in tqdm_notebook(df_1.iterrows()):\n",
    "#     result = netGetGeocoder( addr['주소'])\n",
    "#     if result != None:\n",
    "#         result.append(addr['학교명'])\n",
    "#         university_list.append(result)\n",
    "        \n",
    "# print(len(university_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN    688\n",
      "C       59\n",
      "B       47\n",
      "D       33\n",
      "E       32\n",
      "A       15\n",
      "F       13\n",
      "G        4\n",
      "Name: deck, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# deck열의 NaN 개수 계산하기\n",
    "nan_deck = df['deck'].value_counts(dropna=False)\n",
    "print(nan_deck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass    sex    age  sibsp  parch   fare  embarked  class  \\\n",
      "0     False   False  False  False  False  False  False     False  False   \n",
      "1     False   False  False  False  False  False  False     False  False   \n",
      "2     False   False  False  False  False  False  False     False  False   \n",
      "3     False   False  False  False  False  False  False     False  False   \n",
      "4     False   False  False  False  False  False  False     False  False   \n",
      "\n",
      "     who  adult_male   deck  embark_town  alive  alone  \n",
      "0  False       False   True        False  False  False  \n",
      "1  False       False  False        False  False  False  \n",
      "2  False       False   True        False  False  False  \n",
      "3  False       False  False        False  False  False  \n",
      "4  False       False   True        False  False  False  \n"
     ]
    }
   ],
   "source": [
    "# isnull() 메서드로 누락 데이터 찾기\n",
    "print(df.head().isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass   sex   age  sibsp  parch  fare  embarked  class   who  \\\n",
      "0      True    True  True  True   True   True  True      True   True  True   \n",
      "1      True    True  True  True   True   True  True      True   True  True   \n",
      "2      True    True  True  True   True   True  True      True   True  True   \n",
      "3      True    True  True  True   True   True  True      True   True  True   \n",
      "4      True    True  True  True   True   True  True      True   True  True   \n",
      "\n",
      "   adult_male   deck  embark_town  alive  alone  \n",
      "0        True  False         True   True   True  \n",
      "1        True   True         True   True   True  \n",
      "2        True  False         True   True   True  \n",
      "3        True   True         True   True   True  \n",
      "4        True  False         True   True   True  \n"
     ]
    }
   ],
   "source": [
    "# notnull() 메서드로 누락 데이터 찾기\n",
    "print(df.head().notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "deck           3\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# isnull() 메서드로 누락 데이터 개수 구하기\n",
    "print(df.head().isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived :  0\n",
      "pclass :  0\n",
      "sex :  0\n",
      "age :  177\n",
      "sibsp :  0\n",
      "parch :  0\n",
      "fare :  0\n",
      "embarked :  2\n",
      "class :  0\n",
      "who :  0\n",
      "adult_male :  0\n",
      "deck :  688\n",
      "embark_town :  2\n",
      "alive :  0\n",
      "alone :  0\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 불러오기\n",
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# for 반복문으로 각 열의 NaN 개수 계산하기\n",
    "missing_df = df.isnull()\n",
    "for col in missing_df.columns:\n",
    "    missing_count = missing_df[col].value_counts() # 각 열의 NaN 개수 파악\n",
    "    \n",
    "    try:\n",
    "        print(col, ': ', missing_count[True]) # NaN 값이 있으면 개수를 출력\n",
    "    except:\n",
    "        print(col,': ', 0) # NaN 값이 없으면 0개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# NaN 값이 500개 이상인 열을 모두 삭제 - deck 열(891개중 688개의 NaN값)\n",
    "df_thresh = df.dropna(axis=1, thresh=500)\n",
    "print(df_thresh.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n"
     ]
    }
   ],
   "source": [
    "# age 열에 나이 데이터가 없는 모든 행을 삭제 - age열(891개중 177개의 NaN 값)\n",
    "df_age = df.dropna(subset=['age'], how='any', axis=0)\n",
    "print(len(df_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  survived pclass sex age sibsp parch fare embarked class who adult_male deck  \\\n",
       "0        0      0   0   0     0     0    0        0     0   0          0  NaN   \n",
       "1        1      1   1   1     1     1    1        1     1   1          1    1   \n",
       "2        1      1   1   1     1     1    1        1     1   1          1  NaN   \n",
       "3        1      1   1   1     1     1    1        1     1   1          1    1   \n",
       "4        0      0   0   0     0     0    0        0     0   0          0  NaN   \n",
       "\n",
       "  embark_town alive alone  \n",
       "0           0     0     0  \n",
       "1           1     1     1  \n",
       "2           1     1     1  \n",
       "3           1     1     1  \n",
       "4           0     0     0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = df\n",
    "for col in df.columns:\n",
    "    df_1[col] = df.dropna(subset=[col], how='any', axis=0)\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      "survived       891 non-null object\n",
      "pclass         891 non-null object\n",
      "sex            891 non-null object\n",
      "age            714 non-null object\n",
      "sibsp          891 non-null object\n",
      "parch          891 non-null object\n",
      "fare           891 non-null object\n",
      "embarked       889 non-null object\n",
      "class          891 non-null object\n",
      "who            891 non-null object\n",
      "adult_male     891 non-null object\n",
      "deck           203 non-null object\n",
      "embark_town    889 non-null object\n",
      "alive          891 non-null object\n",
      "alone          891 non-null object\n",
      "dtypes: object(15)\n",
      "memory usage: 104.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    22.0\n",
      "1    38.0\n",
      "2    26.0\n",
      "3    35.0\n",
      "4    35.0\n",
      "5     NaN\n",
      "6    54.0\n",
      "7     2.0\n",
      "8    27.0\n",
      "9    14.0\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['age'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age 열의 Nan값을 다른 나이 데이터의 평균으로 변경하기\n",
    "mean_age = df['age'].mean(axis=0) # age 열의 평균 계산(NaN 값 제외)\n",
    "df['age'].fillna(mean_age, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    22.000000\n",
      "1    38.000000\n",
      "2    26.000000\n",
      "3    35.000000\n",
      "4    35.000000\n",
      "5    29.699118\n",
      "6    54.000000\n",
      "7     2.000000\n",
      "8    27.000000\n",
      "9    14.000000\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# age열의 첫 10개 데이터 출력(5행에 NaN 값이 평균으로 대체)\n",
    "print(df['age'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829            NaN\n",
      "Name: embark_town, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# embark_town 열의 829행의 NaN 데이터 출력\n",
    "print(df['embark_town'][825:830])\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Southampton    646\n",
      "Cherbourg      168\n",
      "Queenstown      77\n",
      "Name: embark_town, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# embark_town 열의 NaN값을 승선도시 중에서 가장 많이 출현한 값으로 치환하기\n",
    "most_freq = df['embark_town'].value_counts(dropna=True)\n",
    "print(most_freq)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Southampton\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# embark_town 열의 NaN값을 승선도시 중에서 가장 많이 출현한 값으로 치환하기\n",
    "most_freq = df['embark_town'].value_counts(dropna=True).idxmax()\n",
    "print(most_freq)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829    Southampton\n",
      "Name: embark_town, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['embark_town'].fillna(most_freq, inplace=True)\n",
    "\n",
    "# embark_town 열 829행의 NaN 데이터 출력(NaN 값이 most_freq 값으로 대체)\n",
    "print(df['embark_town'][825:830])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829            NaN\n",
      "Name: embark_town, dtype: object\n",
      "\n",
      "\n",
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829     Queenstown\n",
      "Name: embark_town, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋 가져오기\n",
    "df = sns.load_dataset('titanic')\n",
    "# embark_town 열의 829행의 NaN 데이터 출력\n",
    "print(df['embark_town'][825:830])\n",
    "print('\\n')\n",
    "#embar_town 열의 NaN값을 바로 앞에 있는 828행의 값으로 변경하기\n",
    "df['embark_town'].fillna(method='ffill', inplace=True)\n",
    "print(df['embark_town'][825:830])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 중복데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "1  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n",
      "4  b   2   2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'c1':['a', 'a', 'b', 'a', 'b'],\n",
    "                    'c2':[1, 1, 1, 2, 2],\n",
    "                    'c3':[1, 1, 2, 2, 2]})\n",
    "print(df)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "dtype: bool\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 프레임 전체 행 데이터중에서 중복값 찾기\n",
    "df_dup = df.duplicated()\n",
    "print(df_dup)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "Name: c2, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임의 특정 열 데이터에서 중복값 찾기\n",
    "col_dup = df['c2'].duplicated()\n",
    "print(col_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  c1  c2  c3\n",
       "0  a   1   1\n",
       "3  a   2   2"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['c2'].duplicated() != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n"
     ]
    }
   ],
   "source": [
    "# c2, c3열을 기준으로 중복 행을 제거\n",
    "df3 =df.drop_duplicates(subset=['c2', 'c3'])\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['130.0' '165.0' '150.0' '140.0' '198.0' '220.0' '215.0' '225.0' '190.0'\n",
      " '170.0' '160.0' '95.00' '97.00' '85.00' '88.00' '46.00' '87.00' '90.00'\n",
      " '113.0' '200.0' '210.0' '193.0' '?' '100.0' '105.0' '175.0' '153.0'\n",
      " '180.0' '110.0' '72.00' '86.00' '70.00' '76.00' '65.00' '69.00' '60.00'\n",
      " '80.00' '54.00' '208.0' '155.0' '112.0' '92.00' '145.0' '137.0' '158.0'\n",
      " '167.0' '94.00' '107.0' '230.0' '49.00' '75.00' '91.00' '122.0' '67.00'\n",
      " '83.00' '78.00' '52.00' '61.00' '93.00' '148.0' '129.0' '96.00' '71.00'\n",
      " '98.00' '115.0' '53.00' '81.00' '79.00' '120.0' '152.0' '102.0' '108.0'\n",
      " '68.00' '58.00' '149.0' '89.00' '63.00' '48.00' '66.00' '139.0' '103.0'\n",
      " '125.0' '133.0' '138.0' '135.0' '142.0' '77.00' '62.00' '132.0' '84.00'\n",
      " '64.00' '74.00' '116.0' '82.00']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read_csv() 함수로 df 생성\n",
    "df = pd.read_csv('./part4/auto-mpg.csv', header=None)\n",
    "\n",
    "# 열 이름을 지정\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year',\n",
    "                'origin', 'name']\n",
    "\n",
    "# horsepower 열의 고유값 확인\n",
    "print(df['horsepower'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['horsepower'].replace('?', np.nan, inplace=True) #'?'을 np.nan으로 변경\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True) # 누락데이터 행을 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['horsepower'] = df['horsepower'].astype('float') #문자열을 실수형으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# horsepower 열의 자료형 확인\n",
    "print(df['horsepower'].dtypes)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 2]\n"
     ]
    }
   ],
   "source": [
    "# origin 열의 고유값 확인\n",
    "print(df['origin'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수형 데이터를 문자형 데이터로 변환\n",
    "df['origin'].replace({1:'USA', 2:'EU', 3:'JAPAN'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['USA' 'JAPAN' 'EU']\n",
      "object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# origin 열의 고유값과 자료형 확인\n",
    "print(df['origin'].unique())\n",
    "print(df['origin'].dtypes)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n"
     ]
    }
   ],
   "source": [
    "# origin 열의 문자열 자료형을 범주형으로 변환\n",
    "df['origin'] = df['origin'].astype('category')\n",
    "print(df['origin'].dtypes)\n",
    "\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201    76\n",
      "228    77\n",
      "181    75\n",
      "Name: model year, dtype: int64\n",
      "105    73\n",
      "280    79\n",
      "355    81\n",
      "Name: model year, dtype: category\n",
      "Categories (13, int64): [70, 71, 72, 73, ..., 79, 80, 81, 82]\n"
     ]
    }
   ],
   "source": [
    "# model year 열의 정수형을 범주형으로 변환\n",
    "print(df['model year'].sample(3))\n",
    "df['model year'] = df['model year'].astype('category')\n",
    "print(df['model year'].sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read_csv() 함수로 df 생성\n",
    "df = pd.read_csv('./part4/auto-mpg.csv', header=None)\n",
    "\n",
    "# 열 이름을 지정\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year',\n",
    "                'origin', 'name']\n",
    "\n",
    "# horsepower 열의 누락 데이터('?') 삭제하고 실수형으로 변환\n",
    "df['horsepower'].replace('?', np.nan, inplace=True) # '?'dmf np.nan으로 변경\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True) # 누락데이터 행을 삭제\n",
    "df['horsepower'] = df['horsepower'].astype('float') # 문자열을 실수형으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 46.         107.33333333 168.66666667 230.        ]\n"
     ]
    }
   ],
   "source": [
    "# np.histogram 함수로 3개의 bin으로 나누는 경꼐 값의 리스트 구하기\n",
    "count, bin_dividers = np.histogram(df['horsepower'], bins=3)\n",
    "print(bin_dividers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    horsepower hp_bin\n",
      "0        130.0   보통출력\n",
      "1        165.0   보통출력\n",
      "2        150.0   보통출력\n",
      "3        150.0   보통출력\n",
      "4        140.0   보통출력\n",
      "5        198.0    고출력\n",
      "6        220.0    고출력\n",
      "7        215.0    고출력\n",
      "8        225.0    고출력\n",
      "9        190.0    고출력\n",
      "10       170.0    고출력\n",
      "11       160.0   보통출력\n",
      "12       150.0   보통출력\n",
      "13       225.0    고출력\n",
      "14        95.0    저출력\n"
     ]
    }
   ],
   "source": [
    "# 3개의 bin에 이름 지정\n",
    "bin_names = ['저출력', '보통출력', '고출력']\n",
    "\n",
    "# pd.cut 함수로 각 데이터를 3개의 bin에 할당\n",
    "df['hp_bin'] = pd.cut(x=df['horsepower'], #데이터 배열\n",
    "                        bins=bin_dividers, # 경계 값 리스트\n",
    "                        labels=bin_names, # bin 이름\n",
    "                        include_lowest=True) # 첫 경계값 포함\n",
    "\n",
    "# pd.cut 함수로 각 데이터를 3개의 bin에 할당\n",
    "print(df[['horsepower', 'hp_bin']].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hp_bin  저출력  보통출력  고출력\n",
      "0         0     1    0\n",
      "1         0     1    0\n",
      "2         0     1    0\n",
      "3         0     1    0\n",
      "4         0     1    0\n",
      "5         0     0    1\n",
      "6         0     0    1\n",
      "7         0     0    1\n",
      "8         0     0    1\n",
      "9         0     0    1\n",
      "10        0     0    1\n",
      "11        0     1    0\n",
      "12        0     1    0\n",
      "13        0     0    1\n",
      "14        1     0    0\n"
     ]
    }
   ],
   "source": [
    "# hp_bin 열의 범주형 데이터를 더미 변수로 변환\n",
    "horsepower_dummies = pd.get_dummies(df['hp_bin'])\n",
    "print(horsepower_dummies.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3개의 bin에 이름 지정\n",
    "bin_names = ['저출력', '보통출력', '고출력']\n",
    "\n",
    "# pd.cut 함수로 각 데이터를 3개의 bin에 할당\n",
    "df['hp_bin'] = pd.cut(x=df['horsepower'], #데이터 배열\n",
    "                        bins=bin_dividers, # 경계 값 리스트\n",
    "                        labels=bin_names, # bin 이름\n",
    "                        include_lowest=True) # 첫 경계값 포함\n",
    "\n",
    "# sklern  라이브러리 불러오기\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 전처리를 위한 encoder 객체 만들기\n",
    "label_encoder = preprocessing.LabelEncoder() # label encoder 생성\n",
    "onehot_encoder = preprocessing.OneHotEncoder() # one hot encoder 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 0 0 0 0 0 1 1 0 2]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# label encoder로 문자열 범주를 숫자형 범주로 변환\n",
    "onehot_labeled = label_encoder.fit_transform(df['hp_bin'].head(15))\n",
    "print(onehot_labeled)\n",
    "print(type(onehot_labeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [2]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "onehot_reshaped = onehot_labeled.reshape(len(onehot_labeled), 1)\n",
    "print(onehot_reshaped)\n",
    "print(type(onehot_reshaped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.565217\n",
      "1    0.717391\n",
      "2    0.652174\n",
      "3    0.652174\n",
      "4    0.608696\n",
      "Name: horsepower, dtype: float64\n",
      "\n",
      "\n",
      "count    392.000000\n",
      "mean       0.454215\n",
      "std        0.167353\n",
      "min        0.200000\n",
      "25%        0.326087\n",
      "50%        0.406522\n",
      "75%        0.547826\n",
      "max        1.000000\n",
      "Name: horsepower, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# horserpower 열의 최대값의 절대값으로 모든 데이터를 나눠서 저장\n",
    "df.horsepower = df.horsepower / abs(df.horsepower.max())\n",
    "\n",
    "print(df.horsepower.head())\n",
    "print('\\n')\n",
    "print(df.horsepower.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.565217\n",
      "1    0.717391\n",
      "2    0.652174\n",
      "3    0.652174\n",
      "4    0.608696\n",
      "Name: horsepower, dtype: float64\n",
      "\n",
      "\n",
      "count    392.000000\n",
      "mean       0.454215\n",
      "std        0.167353\n",
      "min        0.200000\n",
      "25%        0.326087\n",
      "50%        0.406522\n",
      "75%        0.547826\n",
      "max        1.000000\n",
      "Name: horsepower, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# horserpower의 최소를 빼고, 최대에서 최소를 빼서 그값으로 나누어 저장\n",
    "min_x = df.horsepower - df.horsepower.min()\n",
    "min_max = df.horsepower.max() - df.horsepower.min()\n",
    "df.horserpower = min_x / min_max\n",
    "\n",
    "print(df.horsepower.head())\n",
    "print('\\n')\n",
    "print(df.horsepower.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-d36e0ae55389>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# 문자열데이터(시리즈 객체)를 판다스 Timestamp로 변환\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'new_Date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#df에 새로운 열로 추가\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# 데이터 내용 및 자료형 확인\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read_csv() 함수로 df 생성\n",
    "df = pd.read_csv('./part4/stock-data.csv', header=None)\n",
    "\n",
    "# 문자열데이터(시리즈 객체)를 판다스 Timestamp로 변환\n",
    "df['new_Date'] = pd.to_datetime(df['Date']) #df에 새로운 열로 추가\n",
    "\n",
    "# 데이터 내용 및 자료형 확인\n",
    "print(df.head())\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "print(type(df['new_Date'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['new_Date'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-d22d9fd7e21f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 시계열 값으로 변환된 열을 새로운 행 인덱스로 지정, 기존 날짜 열은 삭제\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'new_Date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mset_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   4394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4396\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"None of {} are in the columns\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of ['new_Date'] are in the columns\""
     ]
    }
   ],
   "source": [
    "# 시계열 값으로 변환된 열을 새로운 행 인덱스로 지정, 기존 날짜 열은 삭제\n",
    "df.set_index('new_Date', inplace=True)\n",
    "df.drop('Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0      1      2      3      4       5\n",
      "0        Date  Close  Start   High    Low  Volume\n",
      "1  2018-07-02  10100  10850  10900  10000  137977\n",
      "2  2018-06-29  10700  10550  10900   9990  170253\n",
      "3  2018-06-28  10400  10900  10950  10150  155769\n",
      "4  2018-06-27  10900  10800  11050  10500  133548\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21 entries, 0 to 20\n",
      "Data columns (total 6 columns):\n",
      "0    21 non-null object\n",
      "1    21 non-null object\n",
      "2    21 non-null object\n",
      "3    21 non-null object\n",
      "4    21 non-null object\n",
      "5    21 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 1.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-01-01', '2020-03-01', '2021-06-01'], dtype='datetime64[ns]', freq=None)\n",
      "\n",
      "\n",
      "DatetimeIndex(['2019-01-01', '2020-03-01', '2021-06-01'], dtype='datetime64[ns]', freq=None)\n",
      "\n",
      "\n",
      "PeriodIndex(['2019-01-01', '2020-03-01', '2021-06-01'], dtype='period[D]', freq='D')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dates = ['2019-01-01', '2020-03-01', '2021-06-01']\n",
    "# 날짜 형식의 문자열로 구성되는 리스트 정의\n",
    "ts_dates = pd.to_datetime(dates)\n",
    "print(ts_dates)\n",
    "print('\\n')\n",
    "\n",
    "# 문자열 데이터(시리즈 객체)를 판다스 Timestamp로 변환\n",
    "ts_dates = pd.to_datetime(dates)\n",
    "print(ts_dates)\n",
    "print('\\n')\n",
    "\n",
    "# Timestamp를 Period로 변환\n",
    "pr_day = ts_dates.to_period(freq='D')\n",
    "print(pr_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeriodIndex(['2019-01', '2020-03', '2021-06'], dtype='period[M]', freq='M')\n",
      "PeriodIndex(['2019', '2020', '2021'], dtype='period[A-DEC]', freq='A-DEC')\n"
     ]
    }
   ],
   "source": [
    "pr_month = ts_dates.to_period(freq='M')\n",
    "print(pr_month)\n",
    "\n",
    "pr_year = ts_dates.to_period(freq='A')\n",
    "print(pr_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-01-01 00:00:00+09:00', '2019-02-01 00:00:00+09:00',\n",
      "               '2019-03-01 00:00:00+09:00', '2019-04-01 00:00:00+09:00',\n",
      "               '2019-05-01 00:00:00+09:00', '2019-06-01 00:00:00+09:00'],\n",
      "              dtype='datetime64[ns, Asia/Seoul]', freq='MS')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TImestamp의 배열 만들기 - 월 간격. 월의 시작일 기준\n",
    "ts_ms = pd.date_range(start='2019-01-01',# 날짜 범위의 시작\n",
    "                        end=None, # 날짜 범위 끝\n",
    "                         periods=6, # 생성할 TImestamp의 개수\n",
    "                         freq='MS', # 시간 간격(MS: 월의 시작일)\n",
    "                         tz='Asia/Seoul') # 시간대 (Timezone)\n",
    "print(ts_ms)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-01-31 00:00:00+09:00', '2019-02-28 00:00:00+09:00',\n",
      "               '2019-03-31 00:00:00+09:00', '2019-04-30 00:00:00+09:00',\n",
      "               '2019-05-31 00:00:00+09:00', '2019-06-30 00:00:00+09:00'],\n",
      "              dtype='datetime64[ns, Asia/Seoul]', freq='M')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 월 간격, 월의 마지막 날 기준\n",
    "ts_me = pd.date_range('2019-01-01', periods=6,\n",
    "                        freq='M', # 시간 간격(M: 월의 마지막날)\n",
    "                         tz='Asia/Seoul') # 시간대(Timezone)\n",
    "print(ts_me)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-01-31 00:00:00+09:00', '2019-04-30 00:00:00+09:00',\n",
      "               '2019-07-31 00:00:00+09:00', '2019-10-31 00:00:00+09:00',\n",
      "               '2020-01-31 00:00:00+09:00', '2020-04-30 00:00:00+09:00'],\n",
      "              dtype='datetime64[ns, Asia/Seoul]', freq='3M')\n"
     ]
    }
   ],
   "source": [
    "# 분기(3개월) 간격, 월의 마지막날 기준\n",
    "ts_3m = pd.date_range('2019-01-01', periods=6,\n",
    "                        freq='3M', # 시간 간격(3개월)\n",
    "                         tz='Asia/Seoul') # 시간대(Timezone)\n",
    "print(ts_3m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeriodIndex(['2019-01', '2019-02', '2019-03'], dtype='period[M]', freq='M')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Peroid 배열 만들기 - 1개월 길이\n",
    "pr_m = pd.period_range(start='2019-01-01',# 날짜 범위의 시작\n",
    "                        end=None, # 날짜 범위 끝\n",
    "                         periods=3, # 생성할 Period 개수\n",
    "                         freq='M', # 기간의 길이 (M: 월)\n",
    "                      )\n",
    "                       \n",
    "print(pr_m)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeriodIndex(['2019-01', '2019-02', '2019-03'], dtype='period[M]', freq='M')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Peroid 배열 만들기 - 1시간 길이\n",
    "pr_h = pd.period_range(start='2019-01-01',# 날짜 범위의 시작\n",
    "                        end=None, # 날짜 범위 끝\n",
    "                         periods=3, # 생성할 Period 개수\n",
    "                         freq='H', # 기간의 길이 (H : 시간)\n",
    "                      )           \n",
    "print(pr_m)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeriodIndex(['2019-01-01 00:00', '2019-01-01 02:00', '2019-01-01 04:00'], dtype='period[2H]', freq='2H')\n"
     ]
    }
   ],
   "source": [
    "# Peroid 배열 만들기 - 2시간 길이\n",
    "pr_2h = pd.period_range(start='2019-01-01',# 날짜 범위의 시작\n",
    "                        end=None, # 날짜 범위 끝\n",
    "                         periods=3, # 생성할 Period 개수\n",
    "                         freq='2H', # 기간의 길이 (H : 시간)\n",
    "                      )\n",
    "print(pr_2h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Start</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-07-02</td>\n",
       "      <td>10100</td>\n",
       "      <td>10850</td>\n",
       "      <td>10900</td>\n",
       "      <td>10000</td>\n",
       "      <td>137977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-29</td>\n",
       "      <td>10700</td>\n",
       "      <td>10550</td>\n",
       "      <td>10900</td>\n",
       "      <td>9990</td>\n",
       "      <td>170253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-06-28</td>\n",
       "      <td>10400</td>\n",
       "      <td>10900</td>\n",
       "      <td>10950</td>\n",
       "      <td>10150</td>\n",
       "      <td>155769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-06-27</td>\n",
       "      <td>10900</td>\n",
       "      <td>10800</td>\n",
       "      <td>11050</td>\n",
       "      <td>10500</td>\n",
       "      <td>133548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-06-26</td>\n",
       "      <td>10800</td>\n",
       "      <td>10900</td>\n",
       "      <td>11000</td>\n",
       "      <td>10700</td>\n",
       "      <td>63039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Close  Start   High    Low  Volume\n",
       "0  2018-07-02  10100  10850  10900  10000  137977\n",
       "1  2018-06-29  10700  10550  10900   9990  170253\n",
       "2  2018-06-28  10400  10900  10950  10150  155769\n",
       "3  2018-06-27  10900  10800  11050  10500  133548\n",
       "4  2018-06-26  10800  10900  11000  10700   63039"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read_csv() 함수로 df 생성\n",
    "df = pd.read_csv('./part4/stock-data.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Close  Start   High    Low  Volume   new_Date\n",
      "0  2018-07-02  10100  10850  10900  10000  137977 2018-07-02\n",
      "1  2018-06-29  10700  10550  10900   9990  170253 2018-06-29\n",
      "2  2018-06-28  10400  10900  10950  10150  155769 2018-06-28\n",
      "3  2018-06-27  10900  10800  11050  10500  133548 2018-06-27\n",
      "4  2018-06-26  10800  10900  11000  10700   63039 2018-06-26\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 문자열인 날짜 데이터를 판다스 Timestamp로 변환\n",
    "df['new_Date'] = pd.to_datetime(df['Date'])\n",
    "print(df.head())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Close  Start   High    Low  Volume   new_Date  Year  Month  Day\n",
      "0  2018-07-02  10100  10850  10900  10000  137977 2018-07-02  2018      7    2\n",
      "1  2018-06-29  10700  10550  10900   9990  170253 2018-06-29  2018      6   29\n",
      "2  2018-06-28  10400  10900  10950  10150  155769 2018-06-28  2018      6   28\n",
      "3  2018-06-27  10900  10800  11050  10500  133548 2018-06-27  2018      6   27\n",
      "4  2018-06-26  10800  10900  11000  10700   63039 2018-06-26  2018      6   26\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dt 속성을 이용하여 new_Date 열의 년월일 정보를 년, 월, 일로 구분\n",
    "df['Year'] = df['new_Date'].dt.year\n",
    "df['Month'] = df['new_Date'].dt.month\n",
    "df['Day'] = df['new_Date'].dt.day\n",
    "print(df.head())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Close  Start   High    Low  Volume   new_Date  Year  Month  \\\n",
      "0  2018-07-02  10100  10850  10900  10000  137977 2018-07-02  2018      7   \n",
      "1  2018-06-29  10700  10550  10900   9990  170253 2018-06-29  2018      6   \n",
      "2  2018-06-28  10400  10900  10950  10150  155769 2018-06-28  2018      6   \n",
      "3  2018-06-27  10900  10800  11050  10500  133548 2018-06-27  2018      6   \n",
      "4  2018-06-26  10800  10900  11000  10700   63039 2018-06-26  2018      6   \n",
      "\n",
      "   Day Date_yr   Date_m  \n",
      "0    2    2018  2018-07  \n",
      "1   29    2018  2018-06  \n",
      "2   28    2018  2018-06  \n",
      "3   27    2018  2018-06  \n",
      "4   26    2018  2018-06  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Timestamp를 Period로 변환하여 년월일 표기 변경하기\n",
    "df['Date_yr'] = df['new_Date'].dt.to_period(freq='A')\n",
    "df['Date_m'] = df['new_Date'].dt.to_period(freq='M')\n",
    "print(df.head())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Date  Close  Start   High    Low  Volume   new_Date  Year  \\\n",
      "Date_m                                                                     \n",
      "2018-07  2018-07-02  10100  10850  10900  10000  137977 2018-07-02  2018   \n",
      "2018-06  2018-06-29  10700  10550  10900   9990  170253 2018-06-29  2018   \n",
      "2018-06  2018-06-28  10400  10900  10950  10150  155769 2018-06-28  2018   \n",
      "2018-06  2018-06-27  10900  10800  11050  10500  133548 2018-06-27  2018   \n",
      "2018-06  2018-06-26  10800  10900  11000  10700   63039 2018-06-26  2018   \n",
      "\n",
      "         Month  Day Date_yr  \n",
      "Date_m                       \n",
      "2018-07      7    2    2018  \n",
      "2018-06      6   29    2018  \n",
      "2018-06      6   28    2018  \n",
      "2018-06      6   27    2018  \n",
      "2018-06      6   26    2018  \n"
     ]
    }
   ],
   "source": [
    "# 원하는 열을 새로운 행 인덱스로 지정\n",
    "df.set_index('Date_m', inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Date  Close  Start   High    Low  Volume  Year  Month  Day  \\\n",
      "new_Date                                                                       \n",
      "2018-07-02  2018-07-02  10100  10850  10900  10000  137977  2018      7    2   \n",
      "2018-06-29  2018-06-29  10700  10550  10900   9990  170253  2018      6   29   \n",
      "2018-06-28  2018-06-28  10400  10900  10950  10150  155769  2018      6   28   \n",
      "2018-06-27  2018-06-27  10900  10800  11050  10500  133548  2018      6   27   \n",
      "2018-06-26  2018-06-26  10800  10900  11000  10700   63039  2018      6   26   \n",
      "\n",
      "           Date_yr  \n",
      "new_Date            \n",
      "2018-07-02    2018  \n",
      "2018-06-29    2018  \n",
      "2018-06-28    2018  \n",
      "2018-06-27    2018  \n",
      "2018-06-26    2018  \n",
      "\n",
      "\n",
      "DatetimeIndex(['2018-07-02', '2018-06-29', '2018-06-28', '2018-06-27',\n",
      "               '2018-06-26', '2018-06-25', '2018-06-22', '2018-06-21',\n",
      "               '2018-06-20', '2018-06-19', '2018-06-18', '2018-06-15',\n",
      "               '2018-06-14', '2018-06-12', '2018-06-11', '2018-06-08',\n",
      "               '2018-06-07', '2018-06-05', '2018-06-04', '2018-06-01'],\n",
      "              dtype='datetime64[ns]', name='new_Date', freq=None)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 문자열인 날짜 데이터를 판다스 TimeStamp로 변환\n",
    "df['new_Date'] = pd.to_datetime(df['Date']) # 새로운 열에 추가\n",
    "df.set_index('new_Date', inplace=True) # 행 인덱스로 지정\n",
    "\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "print(df.index)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Date  Close  Start   High    Low  Volume  Year  Month  Day  \\\n",
      "new_Date                                                                       \n",
      "2018-07-02  2018-07-02  10100  10850  10900  10000  137977  2018      7    2   \n",
      "2018-06-29  2018-06-29  10700  10550  10900   9990  170253  2018      6   29   \n",
      "2018-06-28  2018-06-28  10400  10900  10950  10150  155769  2018      6   28   \n",
      "2018-06-27  2018-06-27  10900  10800  11050  10500  133548  2018      6   27   \n",
      "2018-06-26  2018-06-26  10800  10900  11000  10700   63039  2018      6   26   \n",
      "\n",
      "           Date_yr  \n",
      "new_Date            \n",
      "2018-07-02    2018  \n",
      "2018-06-29    2018  \n",
      "2018-06-28    2018  \n",
      "2018-06-27    2018  \n",
      "2018-06-26    2018  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 날짜 인덱스를 이용하여 데이터 선택하기\n",
    "df_y = df['2018']\n",
    "print(df_y.head())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Date  Close  Start   High    Low  Volume  Year  Month  Day  \\\n",
      "new_Date                                                                       \n",
      "2018-07-02  2018-07-02  10100  10850  10900  10000  137977  2018      7    2   \n",
      "\n",
      "           Date_yr  \n",
      "new_Date            \n",
      "2018-07-02    2018  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ym = df.loc['2018-07'] # Loc 인덱서 활용\n",
    "print(df_ym)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Start   High\n",
      "new_Date                \n",
      "2018-07-02  10850  10900\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ym_cols = df.loc['2018-07', 'Start':'High'] # 열범위 슬라이싱\n",
    "print(df_ym_cols)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Date  Close  Start   High    Low  Volume  Year  Month  Day  \\\n",
      "new_Date                                                                       \n",
      "2018-07-02  2018-07-02  10100  10850  10900  10000  137977  2018      7    2   \n",
      "\n",
      "           Date_yr  \n",
      "new_Date            \n",
      "2018-07-02    2018  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ymd = df['2018-07-02']\n",
    "print(df_ymd)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Date  Close  Start   High    Low  Volume  Year  Month  Day  \\\n",
      "new_Date                                                                       \n",
      "2018-06-25  2018-06-25  11150  11400  11450  11000   55519  2018      6   25   \n",
      "2018-06-22  2018-06-22  11300  11250  11450  10750  134805  2018      6   22   \n",
      "2018-06-21  2018-06-21  11200  11350  11750  11200  133002  2018      6   21   \n",
      "2018-06-20  2018-06-20  11550  11200  11600  10900  308596  2018      6   20   \n",
      "\n",
      "           Date_yr  \n",
      "new_Date            \n",
      "2018-06-25    2018  \n",
      "2018-06-22    2018  \n",
      "2018-06-21    2018  \n",
      "2018-06-20    2018  \n"
     ]
    }
   ],
   "source": [
    "df_ymd_range = df['2018-06-25':'2018-06-20'] # 날짜 범위 지정\n",
    "print(df_ymd_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Date  Close  Start   High    Low  Volume  Year  Month  Day  \\\n",
      "time_delta                                                                     \n",
      "180 days    2018-06-28  10400  10900  10950  10150  155769  2018      6   28   \n",
      "181 days    2018-06-27  10900  10800  11050  10500  133548  2018      6   27   \n",
      "182 days    2018-06-26  10800  10900  11000  10700   63039  2018      6   26   \n",
      "183 days    2018-06-25  11150  11400  11450  11000   55519  2018      6   25   \n",
      "186 days    2018-06-22  11300  11250  11450  10750  134805  2018      6   22   \n",
      "187 days    2018-06-21  11200  11350  11750  11200  133002  2018      6   21   \n",
      "188 days    2018-06-20  11550  11200  11600  10900  308596  2018      6   20   \n",
      "189 days    2018-06-19  11300  11850  11950  11300  180656  2018      6   19   \n",
      "\n",
      "           Date_yr  \n",
      "time_delta          \n",
      "180 days      2018  \n",
      "181 days      2018  \n",
      "182 days      2018  \n",
      "183 days      2018  \n",
      "186 days      2018  \n",
      "187 days      2018  \n",
      "188 days      2018  \n",
      "189 days      2018  \n"
     ]
    }
   ],
   "source": [
    "# 시간 간격 계산, 최근 180일 ~ 189일 사이의 값들만 선택하기\n",
    "today = pd.to_datetime('2018-12-25') # 기준일 생성 \n",
    "df['time_delta'] = today - df.index # 날짜 차이 계산\n",
    "df.set_index('time_delta', inplace=True) # 행 인덱스로 지정\n",
    "df_180 = df['180 days':'189 days']\n",
    "print(df_180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 함수 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     fare  ten\n",
      "0  22.0   7.2500   10\n",
      "1  38.0  71.2833   10\n",
      "2  26.0   7.9250   10\n",
      "3  35.0  53.1000   10\n",
      "4  35.0   8.0500   10\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "titanic = sns.load_dataset('titanic')\n",
    "df = titanic.loc[:, ['age', 'fare']]\n",
    "df['ten'] = 10\n",
    "print(df.head())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 사용자 함수 정의\n",
    "def add_10(n): # 10을 더하는 함수\n",
    "    return n + 10\n",
    "\n",
    "def add_two_obj(a,b): # 두 객체의 합\n",
    "    return a + b\n",
    "\n",
    "print(add_10(10))\n",
    "print(add_two_obj(10,10))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    32.0\n",
      "1    48.0\n",
      "2    36.0\n",
      "3    45.0\n",
      "4    45.0\n",
      "Name: age, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 시리즈 객체에 적용\n",
    "sr1 = df['age'].apply(add_10) # n = df['age']의 모든 원소( 특정 컬럼에 함수를 적용 시키고 싶을때)\n",
    "print(sr1.head())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    32.0\n",
      "1    48.0\n",
      "2    36.0\n",
      "3    45.0\n",
      "4    45.0\n",
      "Name: age, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 시리즈 객체와 숫자에 적용 : 2개의 인수(시리즈 + 숫자)\n",
    "sr2 = df['age'].apply(add_two_obj, b=10) #a=df['age']의 모든 원소, b=10\n",
    "print(sr2.head())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    32.0\n",
      "1    48.0\n",
      "2    36.0\n",
      "3    45.0\n",
      "4    45.0\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 람다 함수 활용: 시리즈 객체에 적용\n",
    "sr3 = df['age'].apply(lambda x: add_10(x)) #x=df['age']\n",
    "print(sr3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     fare\n",
      "0  22.0   7.2500\n",
      "1  38.0  71.2833\n",
      "2  26.0   7.9250\n",
      "3  35.0  53.1000\n",
      "4  35.0   8.0500\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋에서 age, fare 2개 열을 선택하여 데이터프레임 만들기\n",
    "titanic = sns.load_dataset('titanic')\n",
    "df = titanic.loc[:, ['age','fare']]\n",
    "print(df.head())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 함수 정의\n",
    "def add_10(n): # 10을 더하는 함수\n",
    "    return n + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     fare\n",
      "0  32.0  17.2500\n",
      "1  48.0  81.2833\n",
      "2  36.0  17.9250\n",
      "3  45.0  63.1000\n",
      "4  45.0  18.0500\n"
     ]
    }
   ],
   "source": [
    "# 데이터프렘이에 applymap()으로 add_10() 함수를 매핑 적용\n",
    "df_map = df.applymap(add_10)\n",
    "print(df_map.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print((lambda a, b : a+b)(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lambda n,m: n if n%2==0 else m)(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "l = list(range(1,11))\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n"
     ]
    }
   ],
   "source": [
    "m = list(map(lambda n:n*n, l))\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "f = list(filter(lambda n:n%2==0, l))\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3628800"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "r = functools.reduce(lambda n,m : n*m, l)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     fare\n",
      "0  22.0   7.2500\n",
      "1  38.0  71.2833\n",
      "2  26.0   7.9250\n",
      "3  35.0  53.1000\n",
      "4  35.0   8.0500\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋에서 age, fare 2개 열을 선택하여 데이터프레임 만들기\n",
    "titanic = sns.load_dataset('titanic')\n",
    "df = titanic.loc[:, ['age','fare']]\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age   fare\n",
      "0  False  False\n",
      "1  False  False\n",
      "2  False  False\n",
      "3  False  False\n",
      "4  False  False\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# 사용자 함수 정의\n",
    "def missing_value(series): # 시리즈를 인수로 전달\n",
    "    return series.isnull() # 불린 시리즈를 반환\n",
    "\n",
    "# 데이터프레임의 각 열을 인수로 전달하면 데이터프레임을 반환\n",
    "result = df.apply(missing_value, axis=0)\n",
    "print(result.head())\n",
    "print('\\n')\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     fare\n",
      "0  22.0   7.2500\n",
      "1  38.0  71.2833\n",
      "2  26.0   7.9250\n",
      "3  35.0  53.1000\n",
      "4  35.0   8.0500\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋에서 age, fare 2개 열을 선택하여 데이터프레임 만들기\n",
    "titanic = sns.load_dataset('titanic')\n",
    "df = titanic.loc[:, ['age','fare']]\n",
    "print(df.head())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age      79.5800\n",
      "fare    512.3292\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# 사용자 함수 정의\n",
    "def min_max(x):\n",
    "    return x.max() - x.min() #최대값 - 최소값\n",
    "\n",
    "# 데이터프레임의 각 열을 인수로 전달하면 시리즈를 반환\n",
    "result = df.apply(min_max) #기본값 axis=0\n",
    "print(result)\n",
    "print('\\n')\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     fare  ten\n",
      "0  22.0   7.2500   10\n",
      "1  38.0  71.2833   10\n",
      "2  26.0   7.9250   10\n",
      "3  35.0  53.1000   10\n",
      "4  35.0   8.0500   10\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋에서 age, fare 2개 열을 선택하여 데이터프레임 만들기\n",
    "titanic = sns.load_dataset('titanic')\n",
    "df = titanic.loc[:, ['age','fare']]\n",
    "df['ten'] = 10\n",
    "print(df.head())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     fare  ten   add\n",
      "0  22.0   7.2500   10  32.0\n",
      "1  38.0  71.2833   10  48.0\n",
      "2  26.0   7.9250   10  36.0\n",
      "3  35.0  53.1000   10  45.0\n",
      "4  35.0   8.0500   10  45.0\n"
     ]
    }
   ],
   "source": [
    "# 사용자 함수 정의\n",
    "def add_two_obj(a, b): # 두 객체의 합\n",
    "    return a + b\n",
    "# 데이터프레임의 2개 열을 선택하여 적용\n",
    "# x=df, a=df['age'], b=df['ten']\n",
    "df['add'] = df.apply(lambda x: add_two_obj(x['age'], x['ten']), axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     fare  ten\n",
      "0  22.0   7.2500   10\n",
      "1  38.0  71.2833   10\n",
      "2  26.0   7.9250   10\n",
      "3  35.0  53.1000   10\n",
      "4  35.0   8.0500   10\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋에서 age, fare 2개 열을 선택하여 데이터프레임 만들기\n",
    "titanic = sns.load_dataset('titanic')\n",
    "df = titanic.loc[:, ['age','fare']]\n",
    "df['ten'] = 10\n",
    "print(df.head())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각열의 NaN 찾기 - 데이터 프레임 전달하면 데이터프레임을 반환\n",
    "def missing_value(x):\n",
    "    return x.isnull()\n",
    "\n",
    "# 각 열의 NaN 개수 반환 - 데이터프레임 전달하면 시리즈 반환\n",
    "def missing_count(x):\n",
    "    return missing_value(x).sum()\n",
    "\n",
    "# 데이터프레임의 총 NaN 개수 - 데이터프레임 전달하면 값을 반환\n",
    "def totoal_number_missing(x):\n",
    "    return missing_count(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age   fare    ten\n",
      "0  False  False  False\n",
      "1  False  False  False\n",
      "2  False  False  False\n",
      "3  False  False  False\n",
      "4  False  False  False\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임에 pipe() 메소드로 함수 매핑\n",
    "result_df = df.pipe(missing_value)\n",
    "print(result_df.head())\n",
    "print(type(result_df))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age     177\n",
      "fare      0\n",
      "ten       0\n",
      "dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_series = df.pipe(missing_count)\n",
    "print(result_series)\n",
    "print(type(result_series))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "result_value = df.pipe(totoal_number_missing)\n",
    "print(result_value)\n",
    "print(type(result_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age\n",
      "0         0       3    male  22.0\n",
      "1         1       1  female  38.0\n",
      "2         1       3  female  26.0\n",
      "3         1       1  female  35.0\n",
      "4         0       3    male  35.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#데이터 프레임 재구성 하기\n",
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋에서 age, fare 2개 열을 선택하여 데이터프레임 만들기\n",
    "titanic = sns.load_dataset('titanic')\n",
    "df = titanic.loc[0:4,'survived':'age']\n",
    "print(df, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['survived', 'pclass', 'sex', 'age'] \n",
      "\n",
      "    age  pclass     sex  survived\n",
      "0  22.0       3    male         0\n",
      "1  38.0       1  female         1\n",
      "2  26.0       3  female         1\n",
      "3  35.0       1  female         1\n",
      "4  35.0       3    male         0 \n",
      "\n",
      "    age     sex  pclass  survived\n",
      "0  22.0    male       3         0\n",
      "1  38.0  female       1         1\n",
      "2  26.0  female       3         1\n",
      "3  35.0  female       1         1\n",
      "4  35.0    male       3         0 \n",
      "\n",
      "   pclass     sex   age  survived\n",
      "0       3    male  22.0         0\n",
      "1       1  female  38.0         1\n",
      "2       3  female  26.0         1\n",
      "3       1  female  35.0         1\n",
      "4       3    male  35.0         0\n"
     ]
    }
   ],
   "source": [
    "# 열이름의 리스트 만들기\n",
    "columns = list(df.columns.values) # 기존 열 이름\n",
    "print(columns, '\\n')\n",
    "\n",
    "# 열 이름을 알파벳 순으로 정렬하기\n",
    "columns_sorted = sorted(columns) # 알파벳 순으로 정렬\n",
    "df_sorted = df[columns_sorted]\n",
    "print(df_sorted, '\\n')\n",
    "\n",
    "# 열 이름을 기존 순서의 정반대 역순으로 정렬하기\n",
    "columns_reversed = list(reversed(columns))\n",
    "df_reversed = df[columns_reversed]\n",
    "print(df_reversed, '\\n')\n",
    "\n",
    "# 열 이름을 사용자가 정의한 임의의 순서로 재배치하기\n",
    "columns_customed = ['pclass', 'sex', 'age', 'survived']\n",
    "df_customed = df[columns_customed]\n",
    "print(df_customed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         연월일   당일종가  전일종가     시가     고가     저가     거래량\n",
      "0 2018-07-02  10100   600  10850  10900  10000  137977\n",
      "1 2018-06-29  10700   300  10550  10900   9990  170253\n",
      "2 2018-06-28  10400   500  10900  10950  10150  155769\n",
      "3 2018-06-27  10900   100  10800  11050  10500  133548\n",
      "4 2018-06-26  10800   350  10900  11000  10700   63039 \n",
      "\n",
      "연월일     datetime64[ns]\n",
      "당일종가             int64\n",
      "전일종가             int64\n",
      "시가               int64\n",
      "고가               int64\n",
      "저가               int64\n",
      "거래량              int64\n",
      "dtype: object \n",
      "\n",
      "0    [2018, 07, 02]\n",
      "1    [2018, 06, 29]\n",
      "2    [2018, 06, 28]\n",
      "3    [2018, 06, 27]\n",
      "4    [2018, 06, 26]\n",
      "Name: 연월일, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('./part6/주가데이터.xlsx')\n",
    "print(df.head(), '\\n')\n",
    "print(df.dtypes, '\\n')\n",
    "\n",
    "# 연, 월, 일 데이터 분리하기\n",
    "df['연월일'] = df['연월일'].astype('str') #문자열 메소드 사용을 자료형 변경\n",
    "dates =df['연월일'].str.split('-') #문자열을 split() 메서드로 분리\n",
    "print(dates.head(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          연월일   당일종가  전일종가     시가     고가     저가     거래량     연   월   일\n",
      "0  2018-07-02  10100   600  10850  10900  10000  137977  2018  07  02\n",
      "1  2018-06-29  10700   300  10550  10900   9990  170253  2018  06  29\n",
      "2  2018-06-28  10400   500  10900  10950  10150  155769  2018  06  28\n",
      "3  2018-06-27  10900   100  10800  11050  10500  133548  2018  06  27\n",
      "4  2018-06-26  10800   350  10900  11000  10700   63039  2018  06  26\n"
     ]
    }
   ],
   "source": [
    "# 분리된 정보를 각각 새로운 열에 담아서 df에 추가하기\n",
    "df['연'] = dates.str.get(0) # dates 변수의 원소 리스트의 0번째 인덱스 값\n",
    "df['월'] = dates.str.get(1) # dates 변수의 원소 리스트의 1번째 인덱스 값\n",
    "df['일'] = dates.str.get(2) # dates 변수의 원소 리스트의 2번째 인덱스 값\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋에서 age, fare 2개 열을 선택하여 데이터프레임 만들기\n",
    "titanic = sns.load_dataset('titanic')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    survived  pclass     sex   age  sibsp  parch      fare embarked   class  \\\n",
      "9          1       2  female  14.0      1      0   30.0708        C  Second   \n",
      "14         0       3  female  14.0      0      0    7.8542        S   Third   \n",
      "22         1       3  female  15.0      0      0    8.0292        Q   Third   \n",
      "27         0       1    male  19.0      3      2  263.0000        S   First   \n",
      "38         0       3  female  18.0      2      0   18.0000        S   Third   \n",
      "\n",
      "      who  adult_male deck  embark_town alive  alone  \n",
      "9   child       False  NaN    Cherbourg   yes  False  \n",
      "14  child       False  NaN  Southampton    no   True  \n",
      "22  child       False  NaN   Queenstown   yes   True  \n",
      "27    man        True    C  Southampton    no  False  \n",
      "38  woman       False  NaN  Southampton    no  False  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 나이가 10대(10~19세)인 승객만 따로 선택\n",
    "mask1 = (titanic.age >= 10) & (titanic.age < 20)\n",
    "df_teenage = titanic.loc[mask1, :]\n",
    "print(df_teenage.head())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     survived  pclass     sex  age  sibsp  parch     fare embarked   class  \\\n",
      "10          1       3  female  4.0      1      1  16.7000        S   Third   \n",
      "24          0       3  female  8.0      3      1  21.0750        S   Third   \n",
      "43          1       2  female  3.0      1      2  41.5792        C  Second   \n",
      "58          1       2  female  5.0      1      2  27.7500        S  Second   \n",
      "119         0       3  female  2.0      4      2  31.2750        S   Third   \n",
      "\n",
      "       who  adult_male deck  embark_town alive  alone  \n",
      "10   child       False    G  Southampton   yes  False  \n",
      "24   child       False  NaN  Southampton    no  False  \n",
      "43   child       False  NaN    Cherbourg   yes  False  \n",
      "58   child       False  NaN  Southampton   yes  False  \n",
      "119  child       False  NaN  Southampton    no  False  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 나이가 10세 미만(0~9세)이고 여성인 승객만 따로 선택\n",
    "mask2 = (titanic.age < 10 ) & (titanic.sex == 'female')\n",
    "df_female_under10 = titanic.loc[mask2, :]\n",
    "print(df_female_under10.head())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age     sex  alone\n",
      "7    2.0    male  False\n",
      "10   4.0  female  False\n",
      "16   2.0    male  False\n",
      "24   8.0  female  False\n",
      "33  66.0    male   True\n"
     ]
    }
   ],
   "source": [
    "# 나이가 10세 미만(0~9세) 또는 60세 이상인 승객의 age, sex, alone 열만 선택\n",
    "mask3 = (titanic.age < 10) | (titanic.age >= 60)\n",
    "df_under10_morethan60 = titanic.loc[mask3, ['age', 'sex', 'alone']]\n",
    "print(df_under10_morethan60.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    survived  pclass     sex   age  sibsp  ...  adult_male  deck  embark_town  \\\n",
      "7          0       3    male   2.0      3  ...       False   NaN  Southampton   \n",
      "16         0       3    male   2.0      4  ...       False   NaN   Queenstown   \n",
      "24         0       3  female   8.0      3  ...       False   NaN  Southampton   \n",
      "27         0       1    male  19.0      3  ...        True     C  Southampton   \n",
      "50         0       3    male   7.0      4  ...       False   NaN  Southampton   \n",
      "\n",
      "   alive  alone  \n",
      "7     no  False  \n",
      "16    no  False  \n",
      "24    no  False  \n",
      "27    no  False  \n",
      "50    no  False  \n",
      "\n",
      "[5 rows x 15 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# titanic 데이터셋에서 age, fare 2개 열을 선택하여 데이터프레임 만들기\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "# IPython 디스플레이 설정 변경 - 출력할 최대 열의 개수\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "# 함께 탑승한 형제 또는 배우자의 수가 3,4,5인 승객만 따로 추출 -불린 인덱싱\n",
    "mask3 = titanic['sibsp'] == 3\n",
    "mask4 = titanic['sibsp'] == 4\n",
    "mask5 = titanic['sibsp'] == 5\n",
    "df_boolean = titanic[mask3 | mask4| mask5]\n",
    "print(df_boolean.head())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    survived  pclass     sex   age  sibsp  ...  adult_male  deck  embark_town  \\\n",
      "7          0       3    male   2.0      3  ...       False   NaN  Southampton   \n",
      "16         0       3    male   2.0      4  ...       False   NaN   Queenstown   \n",
      "24         0       3  female   8.0      3  ...       False   NaN  Southampton   \n",
      "27         0       1    male  19.0      3  ...        True     C  Southampton   \n",
      "50         0       3    male   7.0      4  ...       False   NaN  Southampton   \n",
      "\n",
      "   alive  alone  \n",
      "7     no  False  \n",
      "16    no  False  \n",
      "24    no  False  \n",
      "27    no  False  \n",
      "50    no  False  \n",
      "\n",
      "[5 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "# isin() 메서드 활용하여 동일한 조건으로 추출\n",
    "isin_filter = titanic['sibsp'].isin([3,4,5])\n",
    "df_isin = titanic[isin_filter]\n",
    "print(df_isin.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 프레임 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c\n",
      "0  a0  b0  c0\n",
      "1  a1  b1  c1\n",
      "2  a2  b2  c2\n",
      "3  a3  b3  c3 \n",
      "\n",
      "    a   b   c   d\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  c3\n",
      "4  a4  b4  c4  c4\n",
      "5  a5  b5  c5  c5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({'a' : ['a0', 'a1', 'a2', 'a3'],\n",
    "                    'b' : ['b0', 'b1', 'b2', 'b3'],\n",
    "                    'c' : ['c0', 'c1', 'c2', 'c3']}, \n",
    "                   index=[0,1,2,3])\n",
    "df2 = pd.DataFrame({'a' : ['a2', 'a3', 'a4', 'a5'],\n",
    "                    'b' : ['b2', 'b3', 'b4', 'b5'],\n",
    "                    'c' : ['c2', 'c3', 'c4', 'c5'],\n",
    "                    'd' : ['d2', 'c3', 'c4', 'c5']}, \n",
    "                   index=[2,3,4,5])\n",
    "\n",
    "print(df1, '\\n')\n",
    "print(df2, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c    d\n",
      "0  a0  b0  c0  NaN\n",
      "1  a1  b1  c1  NaN\n",
      "2  a2  b2  c2  NaN\n",
      "3  a3  b3  c3  NaN\n",
      "2  a2  b2  c2   d2\n",
      "3  a3  b3  c3   c3\n",
      "4  a4  b4  c4   c4\n",
      "5  a5  b5  c5   c5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2개의 데이터프레임을 위 아래 행 방향으로 이어 붙이듯 연결하기\n",
    "result1 = pd.concat([df1, df2])\n",
    "print(result1, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c    d\n",
      "0  a0  b0  c0  NaN\n",
      "1  a1  b1  c1  NaN\n",
      "2  a2  b2  c2  NaN\n",
      "3  a3  b3  c3  NaN\n",
      "4  a2  b2  c2   d2\n",
      "5  a3  b3  c3   c3\n",
      "6  a4  b4  c4   c4\n",
      "7  a5  b5  c5   c5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ignore_index = True 옵션 설정하기\n",
    "result2 = pd.concat([df1, df2], ignore_index=True)\n",
    "print(result2, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     a    b    c    a    b    c    d\n",
      "0   a0   b0   c0  NaN  NaN  NaN  NaN\n",
      "1   a1   b1   c1  NaN  NaN  NaN  NaN\n",
      "2   a2   b2   c2   a2   b2   c2   d2\n",
      "3   a3   b3   c3   a3   b3   c3   c3\n",
      "4  NaN  NaN  NaN   a4   b4   c4   c4\n",
      "5  NaN  NaN  NaN   a5   b5   c5   c5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2개의 데이터프레임을 좌우 열 방향으로 이어 붙이듯 연결하기\n",
    "result3 = pd.concat([df1, df2], axis=1)\n",
    "print(result3, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c   a   b   c   d\n",
      "2  a2  b2  c2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  a3  b3  c3  c3 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join='inner' 옵션 적용하기(교집합)\n",
    "result3_in = pd.concat([df1, df2], axis=1, join='inner')\n",
    "print(result3_in, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c   e\n",
      "0  a0  b0  c0  e0\n",
      "1  a1  b1  c1  e1\n",
      "2  a2  b2  c2  e2\n",
      "3  a3  b3  c3  e3 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 시리즈 만들기\n",
    "sr1 = pd.Series(['e0', 'e1', 'e2', 'e3'], name='e')\n",
    "sr2 = pd.Series(['f0', 'f1', 'f2'], name='f', index=[3,4,5])\n",
    "sr3 = pd.Series(['g0', 'g1', 'g2', 'g3'], name='g')\n",
    "\n",
    "# df1와 sr1을 좌우 열 방향으로 연결하기\n",
    "result4 = pd.concat([df1, sr1], axis=1)\n",
    "print(result4, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c   d    f\n",
      "2  a2  b2  c2  d2  NaN\n",
      "3  a3  b3  c3  c3   f0\n",
      "4  a4  b4  c4  c4   f1\n",
      "5  a5  b5  c5  c5   f2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df2과 sr2를 좌우 열방향으로 연결하기\n",
    "result5 = pd.concat([df2, sr2], axis=1, sort=True)\n",
    "print(result5, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    e   g\n",
      "0  e0  g0\n",
      "1  e1  g1\n",
      "2  e2  g2\n",
      "3  e3  g3 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sr1과 sr3를 좌우 열방향으로 연결하기\n",
    "result6 = pd.concat([sr1, sr3], axis=1)\n",
    "print(result6, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    e0\n",
      "1    e1\n",
      "2    e2\n",
      "3    e3\n",
      "0    g0\n",
      "1    g1\n",
      "2    g2\n",
      "3    g3\n",
      "dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "result7 = pd.concat([sr1, sr3], axis=0)\n",
    "print(result7, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
